{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eabf6cb",
   "metadata": {},
   "source": [
    "# Q1: Scrape the details of most viewed videos on YouTube from Wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359add8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"05f66d486aecf6d29aa0a49d16da9530\", element=\"ed3cfe01-58d9-4389-a89f-7bc4b25e426a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"05f66d486aecf6d29aa0a49d16da9530\", element=\"fb2de14e-861e-4bfa-b2ed-51b84238111f\")>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "    \n",
    "tble =driver.find_elements(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]')\n",
    "tble \n",
    " \n",
    "# import pandas as pd\n",
    "# sdf=pd.DataFrame({'Match Title':rows,'Series':cols})\n",
    "# sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89090e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "rank=[]        \n",
    "name=[]\n",
    "artist=[]\n",
    "uploaddate=[]\n",
    "views=[]\n",
    "\n",
    "rank_tags=driver.find_elements(By.XPATH, '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr[1]/td[2]/a')\n",
    "for i in rank_tags[0:10]:\n",
    "    rnk=i.text\n",
    "    rank.append(rnk)\n",
    "    \n",
    "name_tags=driver.find_elements(By.XPATH, '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr[1]/td[2]/a')\n",
    "for i in name_tags[0:10]:\n",
    "    nm=i.text\n",
    "    name.append(nm)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a8a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222bd47",
   "metadata": {},
   "source": [
    "# Q2:Scrape the details teamIndiaâ€™sinternationalfixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1696e5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "bdriver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "bdriver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "inter=bdriver.find_element(By.XPATH, '/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "inter.click()\n",
    "\n",
    "\n",
    "matchtitle=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]\n",
    "\n",
    "match_tags=bdriver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in match_tags[0:10]:\n",
    "    mth=i.text\n",
    "    matchtitle.append(mth)\n",
    "    \n",
    "series_tags=bdriver.find_elements(By.XPATH, '//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in series_tags[0:100]:\n",
    "    sr=i.text\n",
    "    series.append(sr)\n",
    "    \n",
    "place_tags=bdriver.find_elements(By.XPATH, '//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in place_tags[0:100]:\n",
    "    plc=i.text\n",
    "    place.append(plc)\n",
    "    \n",
    "date_tags=bdriver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in date_tags[0:100]:\n",
    "    dt=i.text\n",
    "    date.append(dt)\n",
    "\n",
    "time_tags=bdriver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in time_tags[0:100]:\n",
    "    tm=i.text\n",
    "    time.append(tm)\n",
    "        \n",
    "print(len(matchtitle),len(series),len(place),len(date),len(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f1f9a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP FINAL 2023</td>\n",
       "      <td>Final -</td>\n",
       "      <td>Kennington Oval,</td>\n",
       "      <td>7 JUN 2023</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Match Title   Series             Place  \\\n",
       "0  ICC WORLD TEST CHAMPIONSHIP FINAL 2023  Final -  Kennington Oval,   \n",
       "\n",
       "         Date         Time  \n",
       "0  7 JUN 2023  3:30 PM IST  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Match Title':matchtitle,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f774e",
   "metadata": {},
   "source": [
    "# Q3:Scrape the details of State-wise GDP ofIndia fromstatisticstime.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34a55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "gdriver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "gdriver.get(\"http://statisticstimes.com/\")\n",
    "\n",
    "eco=gdriver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "gdriver.execute_script(\"arguments[0].click();\", eco)\n",
    " \n",
    "try:\n",
    "    e=gdriver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "    el=e.get_attribute('href')\n",
    "    el.click()\n",
    "except NoSuchElementException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcf01b",
   "metadata": {},
   "source": [
    "# Q4:Scrape the details of trending repositories on Github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf6f24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "gitdriver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "gitdriver.get(\"http://github.com/\")\n",
    "\n",
    "rep=gitdriver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "gitdriver.execute_script(\"arguments[0].click();\", rep)\n",
    "\n",
    "title=[]\n",
    "description=[]\n",
    "contricount=[]\n",
    "language=[]\n",
    "\n",
    "title_tags=gitdriver.find_elements(By.XPATH, '//h3[@class=\"h3 lh-condensed\"]') \n",
    "for i in title_tags:\n",
    "    ttl=i.text\n",
    "    title.append(ttl)\n",
    "    \n",
    "desc_tags=gitdriver.find_elements(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in desc_tags:\n",
    "    des=i.text\n",
    "    description.append(des)\n",
    "    \n",
    "con_tags=gitdriver.find_elements(By.XPATH, '/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article[1]/div[2]/a')\n",
    "for i in con_tags:\n",
    "    co=i.text\n",
    "    contricount.append(co)\n",
    "\n",
    "lan_tags=gitdriver.find_elements(By.XPATH, '//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "for i in lan_tags:\n",
    "    lan=i.text\n",
    "    language.append(lan)\n",
    "    \n",
    "print(len(title),len(description),len(contricount),len(language))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005b676",
   "metadata": {},
   "source": [
    "# Q5:Scrape the details of top 100 songs on billiboard.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66109d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "bildriver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "bildriver.get(\" https:/www.billboard.com/\")\n",
    "\n",
    "ht=bildriver.find_element(By.XPATH, '//a[@class=\"c-link  lrv-a-unstyle-link a-font-primary-bold lrv-u-font-size-28@desktop-xl lrv-u-font-size-18 lrv-u-color-grey:hover u-padding-a-1@desktop-max lrv-u-padding-b-050\"]')\n",
    "bildriver.execute_script(\"arguments[0].click();\", ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdb2f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chrt=bildriver.find_element(By.XPATH, '//a[@class=\"c-link  lrv-a-unstyle-link lrv-u-background-color-brand-secondary-dark lrv-u-color-grey-lightest lrv-u-color-grey-lightest:hover lrv-u-width-100p lrv-u-text-align-center lrv-a-hover-effect lrv-u-background-color-grey-dark:hover a-font-accent-fancy lrv-u-font-size-20 u-padding-tb-15 u-letter-spacing-0112 lrv-a-icon-after a-icon-magazine lrv-u-justify-content-center lrv-u-align-items-center lrv-a-unstyle-link u-width-100p@tablet u-width-235@mobile-max lrv-u-margin-t-050@mobile-max u-background-color-white@mobile-max u-color-black@mobile-max lrv-u-border-a-1@mobile-max lrv-u-border-color-brand-accent-red u-line-height-1\"]')\n",
    "    bildriver.execute_script(\"arguments[0].click();\", chrt)\n",
    "except NoSuchElementException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95b81be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Songname</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 Leaf Clover</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Songname    Artist Name Last Week Rank Peak Rank Weeks On Board\n",
       "0  5 Leaf Clover  Morgan Wallen                        9             14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songname=[]\n",
    "artistname=[]\n",
    "lastweekrank=[]\n",
    "peakrank=[]\n",
    "weeksonboard=[]\n",
    "\n",
    "song_tags=bildriver.find_elements(By.XPATH, '/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[102]/ul/li[4]/ul/li[1]/h3') \n",
    "for i in song_tags:\n",
    "    sg=i.text\n",
    "    songname.append(sg)\n",
    "    \n",
    "art_tags=bildriver.find_elements(By.XPATH, '/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[108]/ul/li[4]/ul/li[1]/span')\n",
    "for i in art_tags:    \n",
    "    ar=i.text\n",
    "    artistname.append(ar)\n",
    "    \n",
    "lwr_tags=bildriver.find_elements(By.XPATH, '/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[108]/ul/li[4]/ul/li[7]/ul/li[3]/span')\n",
    "for i in lwr_tags:    \n",
    "    r=i.text\n",
    "    lastweekrank.append(r)\n",
    "    \n",
    "peak_tags=bildriver.find_elements(By.XPATH, '/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[5]/span')\n",
    "for i in peak_tags:    \n",
    "    pr=i.text\n",
    "    peakrank.append(pr)\n",
    "\n",
    "week_tags=bildriver.find_elements(By.XPATH, '/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[103]/ul/li[4]/ul/li[6]/span')\n",
    "for i in week_tags:    \n",
    "    wk=i.text\n",
    "    weeksonboard.append(wk)        \n",
    "    \n",
    "\n",
    "print(len(songname),len(artistname),len(lastweekrank),len(peakrank),len(weeksonboard))\n",
    "\n",
    "import pandas as pd\n",
    "sdf=pd.DataFrame({'Songname':songname, 'Artist Name': artistname, 'Last Week Rank':lastweekrank ,'Peak Rank':peakrank ,'Weeks On Board':weeksonboard})\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14affec0",
   "metadata": {},
   "source": [
    "# Q6: Scrape the details of Highest sellingnovels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c64c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "\n",
    "sedriver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "sedriver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "book=sedriver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[1]/td[2]')\n",
    "author=sedriver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[1]/td[3]')\n",
    "vsold=sedriver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[1]/td[4]')\n",
    "pub=sedriver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[1]/td[5]')\n",
    "gen=sedriver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[1]/td[6]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3559a28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"b66b698bd0a74b614305f0d340acea61\", element=\"237abc12-c41f-43d9-b977-8a28a949aa8c\")>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookname=[]\n",
    "authorname=[]\n",
    "volumesold=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "for _ in range(20):\n",
    "    sedriver.execute_script(\"window.scrollBy(0,100)\")\n",
    "    \n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
